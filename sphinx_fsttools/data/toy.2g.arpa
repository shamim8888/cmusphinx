#############################################################################
## Copyright (c) 1996, Carnegie Mellon University, Cambridge University,
## Ronald Rosenfeld and Philip Clarkson
## Version 3, Copyright (c) 2006, Carnegie Mellon University 
## Contributors includes Wen Xu, Ananlada Chotimongkol, 
## David Huggins-Daines, Arthur Chan and Alan Black 
#############################################################################
=============================================================================
===============  This file was produced by the CMU-Cambridge  ===============
===============     Statistical Language Modeling Toolkit     ===============
=============================================================================
This is a 2-gram language model, based on a vocabulary of 4 words,
  which begins "</s>", "<s>", "a"...
This is an OPEN-vocabulary model (type 1)
  (OOVs were mapped to UNK, which is treated as any other vocabulary word)
Good-Turing discounting was applied.
1-gram frequency of frequency : 0 
2-gram frequency of frequency : 1 3 1 0 0 1 0 
1-gram discounting ratios : 
2-gram discounting ratios : 
This file is in the ARPA-standard format introduced by Doug Paul.

p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)
                else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)
                else                         p(wd3|w2)

p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)
            else              bo_wt_1(wd1)*p_1(wd2)

All probs and back-off weights (bo_wt) are given in log10 form.

Data formats:

Beginning of data mark: \data\
ngram 1=nr            # number of 1-grams
ngram 2=nr            # number of 2-grams

\1-grams:
p_1     wd_1 bo_wt_1
\2-grams:
p_2     wd_1 wd_2 

end of data mark: \end\

\data\
ngram 1=5
ngram 2=6

\1-grams:
-99.0000 <UNK>	0.0000
-0.8129 </s>	-0.4771
-99.0000 <s>	0.2109
-0.1597 a	-0.1871
-0.8129 b	0.0348

\2-grams:
-0.1761 </s> <s> 
-0.6021 <s> a 
-0.3010 <s> b 
-0.5229 a </s> 
-0.2218 a a 
-0.1761 b a 

\end\
