
fwdflat sliding window

 * Need to be able to traverse/index backpointer table by start frame
 * I think this might be useful for garbage collection too
 * Seems like we ultimately need multiple "views" over the backpointer table
   - indexes really, so that multiple passes can access it simultaneously

 * Actually what we can do is just refresh the expand word list
   expiring entries with start frames outside the window and adding new ones

 * Alternately we could just sort the backpointer table according to start frame
   How efficient/inefficient is it to do this incrementally in fwdflat?

* Add ability to pull from previous bptbl to fwdflat search
  - Implement arc buffers - DONE
    * Note that this is basically just incremental lattice generation
    * And the same mechanism we'll use for a bunch of other stuff
  - Pipelining requires acmod to be restructured a bit
    * Because s2_semi_mgau is stateful, remembers last frame's topn DONE
  - A couple of options here to think about
    * Separate acmod_t for each search module DONE
      + Would need some kind of COW or ability to share components DONE
      + Probably just add a "clone" function to the acmod_t and mgau_t DONE
      	- Shares fe_t, feat_t DONE
	- Separate mfcc and feat buffers DONE
	- Shares acoustic model parameters DONE
	- Separate senone score arrays and top-N stuff, etc DONE
    * Extend mgau_t interface to be aware of frame indices NOPE
      + For s2_semi_mgau it would probably just keep a history of top-N
      + There would also have to be an API to release old frames
      + This seems somewhat more involved, especially since logically
        we want to have separate acmods for each search component
      + If we wanted to cache senone scores though it might make sense

feature buffering for pipelining

* Current model is "push-pull"
  - Give audio data in blocks to the acmod, which consumes as much as it can
  - Pull feature data out of the acmod and push it to the search module, which
    is assumed to always consume one frame at a time.
  - Explicit frame indices are passed to search modules, which then
    pass them to the acmod, which translates them to relative indices
  - But then we call acmod_advance outside the search modules (!)

* With cloned acmods we don't need to pass explicit frame indices,
  because the phone lookahead can just get its own and act like any
  other search module - which begs the question how shoud a search
  module act?

  - The pulling from the acmod should be done by the search module itself
  - Application fills the acmod's buffers
  - Search module drains the acmod's buffers
    + When search modules run in their own threads, their main loop
      will poll the acmod for frames and process them if possible
    + Seems like there might be a potential for deadlock in here...

    + One potential deadlock situation is where the application fills
      up the acmod buffer, but there are not enough frames of
      lookahead for the final search pass to produce output
      - if bptbl and arc buffers are expandable this is okay
      - the first pass will always accept input	

      - if there is fixed lookahead it needs to be smaller than the
        acmod buffer (the current setup already does this for other
        reasons)

* Step 1: move calls to acmod_advance() into the search code
  + Make a standard way to query available frames in the acmod
  + search step functions now have the possibility to return zero
* Step 2: make code that feeds things to the acmod sensitive to the
  possibility that it might not accept frames (this may already be the
  case except in tests)


Potential idea (no, actually this works)

 * Track oldest backpointer in lexicon tree
   - once it passes frame K, no more words can start in that frame
   - therefore we can reorder the bptbl up to frame K
   - the bptbl is *mostly* sorted, so qsort is a Bad Idea
   - actually we should just heapify it, it is really a priority queue
     which fwdtree feeds and fwdflat and lattice generation pull from
   - actually the decoding pipeline is in fact one big priority queue
     or rather two+ of them chained together
 * So what we can do is just change the backpointer insertion function
   to heapify things
 * The problem with this is that since it's mostly sorted we could do
   much better than O(n log n) to sort it, but that's what heapsort
   gives us
 * So a modified insertion sort seems like the right way to do this

Track the number of inversions in the backpointer table to determine
the best algorithm

Damerau-Levenshtein distance

Make fwdflat work without word_lat_idx

bptr garbage collection

Refactoring:

1) split backpointer table / score stack from ngram search
2) make fwdflat overwrite backpointer table rather than clear it

Insertion sort should be relatively efficient for sorting the
backpointer table since it contains long runs of the same value and is
loosely ordered.

We can speed it up by speeding up the search for an insertion location
- we track the oldest backpointer in the lexicon tree and its
corresponding location in the backpointer table, and there is no need
to search before it for insertion.  This also has the consequence that
all backpointer entries before it are frozen in place and can thus be
converted to lattice nodes or used for fwdflat search.

This gives us one version of the elastic lookahead window.  The other
version uses the "convergence" property of the lattice, which is
defined hence:

---

So we will add another phase to each frame of search, which is sorting
and garbage collection of the lattice (in the future we can hopefully
put this in its own thread) This task gets inserted between fwdflat
and fwdtree, and between fwdtree and bestpath/lattice generation.

---

The problem with this is that when you permute the backpointer table,
you have to rewrite all the references to those backpointers.  This is
one place where the oldest backpointer thing can help - we know that
no new entries will be generated that point to things behind it, so we
are free to reorder everything from it on backwards.  Then we just
have to snap the pointers as part of the insertion operation.

It also means that we can sort everything between the previous oldest
backpointer and the latest one without having to touch anything in the
more distant past, since nothing will point any further back.

I.e. we just insertion sort within variably-sized blocks.

---

We divide the backpointer table into two parts - the oldest part sorts
by start time (needed to do fwdflat search and build word lattice)
while the newest part sorts by end time (needed by fwdtree search).
The ending frame of the oldest active backpointer in the search tree
is the dividing line between the two.

The end-time sorted part constitutes an elastic window within which
phoneme lookahead, fwdtree, and potentially other forward searches (or
parallel ones) operate.

Behind the dividing line is a fixed window in which fwdflat operates.

Behind that, backpointer entries are retired or garbage collected by
the lattice generator.

---

To reduce the length of the elastic window, forcibly break long
silences - if the oldest backpointer in a silence word is too old,
clear its path scores and re-enter it.

Note that if the threshold is too small this can cause errors at the
beginning of the sentence - not sure why this happens (something to do
with scores i guess) but it should be fixable somehow.

---

In practice when we garbage collect the bp table, we obtain a compact
portion followed by a growing gap, then the elastic 'scratchpad'
window.  The backpointer indices before the gap grow much slower than
the ones after it, and can be reassigned as necessary.

We would like to separate these two parts of the bptbl, and use a
rotating buffer for the working window with an expandable vector (or
even a tree) for the compact, static portion.

Also we want the infinitely growable parts such as ef_idx and permute
to, well, not be infinitely growable, instead having a base index that
corresponds to their respective region of applicability.

Another important question is, how important is it to have sequential,
numeric backpointer IDs that directly correspond to memory locations?
If looking up backpointers is not particularly frequent then we could
add a layer of indirection between them and the actual backpointer
table, at which point there is no longer any need to compact it - we
can just use a freelist to allocate new backpointers as needed.

---

ngram_search_exit_score gets called A LOT.  Not sure what to do about
that.

---

Wrote about doing the fixed size bptbl stuff a bunch in the
dissertation draft.  However I haven't really figured out how to do it
yet.  The idea is to combine maxwpf (or really maxhistpf, but in
pocketsphinx these are the same thing) with a duration model, such
that the size of the bptbl is set as maxwpf * longest_word.

The problem is that maxwpf doesn't work right with bptbl and gc.  The
reason for this is that bptbl gc uses the valid flag for gc, so the
maxwpf information gets erased.  This isn't a huge problem since we
have a bunch of bits in that valid flag.

The other issue is that the old maxwpf never actually removed anything
from the bptbl, just marked it as invalid, so if things got screwed up
it wouldn't lead to weird recognition failures.  It *should* be the
case that invalidated bps will never be used to enter successor words
and thus they will never show up in the search graph.

Currently the way the maxwpf works is:

 * Generate a bunch of word exits in final phone pruning
 * Invalidate some of them
 * Use the valid ones to re-enter the search graph

Actually this takes place in a different part of the bptbl - it's only
the entries that have just been generated for the current frame, and
don't yet even have any references in the search graph.  So there
should not be any conflict between this and the bptbl gc, AS LONG AS
the pruned exits are actually removed from the graph before
word_transition is called.

Basically this is an entirely different phase of garbage collection.
In fact, it may be reasonable to split out the current frame's bptbl
entries from the active ones, since they aren't actually active yet,
and since there could potentially be a large number of them - in
theory it could be up to the number of words in the vocabulary.

In this scheme bptbl would work similarly to arc_buffer in that there
will be a "mark" operation (currently bptbl_push_frame()) and a
"commit" operation - in this case rather than sorting, the commit
operation would do pruning.

Okay, this is done.

------

Now we need to figure out how to enforce a hard limit on the size of
the backpointer table.  The duration modeling thing can be done after
this - for the moment we just want to have a parameter to tune (though
we will do the duration modeling, have no doubt about that)
